# 🚀 Nova Carter 導航訓練指令快速參考

> **快速參考**：所有常用訓練和測試指令的完整清單

---

## 📋 目錄

1. [環境準備](#環境準備)
2. [訓練指令](#訓練指令)
3. [測試模型指令](#測試模型指令)
4. [觀察訓練結果](#觀察訓練結果)
5. [查看代碼架構](#查看代碼架構)
6. [常見問題排查](#常見問題排查)

---

## 🔧 環境準備

### 1. 啟動 Isaac Sim 環境

```bash
cd /home/aa/IsaacLab

# 激活 conda 環境
conda activate env_isaaclab
```

### 2. 驗證環境

```bash
# 檢查 Python 路徑（應該顯示 Isaac Sim 的 Python）
./isaaclab.sh -p --version

# 列出可用環境
./isaaclab.sh -p scripts/tools/list_envs.py
```

**預期輸出**：應該看到 `Isaac-Navigation-LocalPlanner-Carter-v0`

---

## 🎓 訓練指令

### 基本訓練（48 個並行環境）⭐

```bash
cd /home/aa/IsaacLab

./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py \
    --task Isaac-Navigation-LocalPlanner-Carter-v0 \
    --num_envs 48 \
    --max_iterations 3000
```

**說明**：
- `--task`：環境名稱
- `--num_envs 48`：並行 48 個環境（推薦 GPU）
- `--max_iterations 3000`：訓練 3000 次迭代（約 60-90 分鐘）

### Headless 模式訓練（無 GUI，更快）⭐

```bash
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py \
    --task Isaac-Navigation-LocalPlanner-Carter-v0 \
    --num_envs 48 \
    --headless
```

**優點**：
- 不渲染畫面，訓練更快
- 適合長時間訓練
- **推薦用於正式訓練**

### GUI 模式訓練（有可視化）

```bash
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py \
    --task Isaac-Navigation-LocalPlanner-Carter-v0 \
    --num_envs 4 \
    --enable_cameras
```

**注意**：
- 使用較少環境（4-8 個）避免卡頓
- 可以觀察訓練過程
- 適合調試和演示

### CPU 訓練（無 GPU 時）

```bash
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py \
    --task Isaac-Navigation-LocalPlanner-Carter-v0 \
    --num_envs 8 \
    --cpu
```

**說明**：
- 減少環境數量（8-16 個）
- 訓練速度較慢
- 僅用於測試

### 從檢查點繼續訓練

```bash
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py \
    --task Isaac-Navigation-LocalPlanner-Carter-v0 \
    --num_envs 48 \
    --resume \
    --load_run logs/rsl_rl/local_planner_carter/2025-10-23_00-43-53
```

**說明**：
- `--resume`：從檢查點繼續
- `--load_run`：指定訓練目錄

### 自訂實驗名稱

```bash
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py \
    --task Isaac-Navigation-LocalPlanner-Carter-v0 \
    --num_envs 48 \
    --run_name "dense_rewards_v2"
```

**結果位置**：`logs/rsl_rl/local_planner_carter/dense_rewards_v2_[時間]`

---

## 🎮 測試模型指令

### 測試訓練好的模型⭐

```bash
cd /home/aa/IsaacLab

./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/play.py \
    --task Isaac-Navigation-LocalPlanner-Carter-v0 \
    --num_envs 1 \
    --checkpoint logs/rsl_rl/local_planner_carter/2025-10-23_00-43-53/model_2999.pt
```

**說明**：
- 使用最終模型（`model_2999.pt`）
- 單個環境（`--num_envs 1`）便於觀察
- **自動開啟 GUI 可視化**

### 測試不同迭代的模型（對比進步）

```bash
# 測試早期模型（第 500 次迭代）
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/play.py \
    --task Isaac-Navigation-LocalPlanner-Carter-v0 \
    --num_envs 1 \
    --checkpoint logs/rsl_rl/local_planner_carter/2025-10-23_00-43-53/model_500.pt

# 測試中期模型（第 1500 次迭代）
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/play.py \
    --task Isaac-Navigation-LocalPlanner-Carter-v0 \
    --num_envs 1 \
    --checkpoint logs/rsl_rl/local_planner_carter/2025-10-23_00-43-53/model_1500.pt

# 測試最終模型（第 2999 次迭代）
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/play.py \
    --task Isaac-Navigation-LocalPlanner-Carter-v0 \
    --num_envs 1 \
    --checkpoint logs/rsl_rl/local_planner_carter/2025-10-23_00-43-53/model_2999.pt
```

### 多環境測試（並行評估）

```bash
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/play.py \
    --task Isaac-Navigation-LocalPlanner-Carter-v0 \
    --num_envs 16 \
    --checkpoint logs/rsl_rl/local_planner_carter/2025-10-23_00-43-53/model_2999.pt
```

**說明**：同時運行 16 個環境，快速評估成功率

### 錄製影片

```bash
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/play.py \
    --task Isaac-Navigation-LocalPlanner-Carter-v0 \
    --num_envs 1 \
    --checkpoint logs/rsl_rl/local_planner_carter/2025-10-23_00-43-53/model_2999.pt \
    --video \
    --video_length 200
```

**結果位置**：`videos/` 目錄

---

## 📊 觀察訓練結果

### 1. 查看訓練日誌（終端輸出）

訓練時的終端會實時顯示：

```
Learning iteration 999/3000
  Mean reward: -2598.61
  Mean episode length: 181.36
  Episode_Reward/reached_goal: 0.00
  Episode_Termination/goal_reached: 0.00
```

### 2. TensorBoard 可視化⭐（推薦）

**啟動 TensorBoard**：

```bash
cd /home/aa/IsaacLab

# 查看所有訓練
tensorboard --logdir logs/rsl_rl/

# 或只查看特定訓練
tensorboard --logdir logs/rsl_rl/local_planner_carter/2025-10-23_00-43-53/
```

**瀏覽器打開**：`http://localhost:6006`

**可查看的曲線**：
- 📈 **Mean Reward**：整體表現趨勢
- 🎯 **Episode_Reward/reached_goal**：成功獎勵
- 📊 **Episode_Termination/goal_reached**：成功率
- ❌ **Episode_Termination/collision**：碰撞率
- ⏱️ **Episode_Termination/time_out**：超時率
- 📉 **Loss/value_function**：Value loss
- 📉 **Loss/surrogate**：Policy loss
- 📉 **Loss/entropy**：Entropy bonus

### 3. 查看訓練結果目錄

```bash
# 列出所有訓練
ls -lh logs/rsl_rl/local_planner_carter/

# 查看最新訓練的內容
ls -lh logs/rsl_rl/local_planner_carter/2025-10-23_00-43-53/
```

**訓練結果包含**：
- `model_*.pt`：模型檢查點（每 100 次迭代保存）
- `events.out.tfevents.*`：TensorBoard 日誌
- `params/`：訓練配置參數
- `git/`：Git 版本信息

### 4. 查看訓練配置

```bash
# 查看環境配置
cat logs/rsl_rl/local_planner_carter/2025-10-23_00-43-53/params/env.json

# 查看演算法配置
cat logs/rsl_rl/local_planner_carter/2025-10-23_00-43-53/params/agent.json
```

---

## 🔍 查看代碼架構

### 1. 查看環境配置文件

```bash
# 完整環境配置（場景、觀測、動作、獎勵）
vim source/isaaclab_tasks/isaaclab_tasks/manager_based/navigation/\
local_planner/local_planner_env_cfg.py

# 快速查看關鍵部分
# 觀測空間（第 163-194 行）
sed -n '163,194p' source/isaaclab_tasks/isaaclab_tasks/manager_based/navigation/\
local_planner/local_planner_env_cfg.py

# 獎勵函數（第 219-261 行）
sed -n '219,261p' source/isaaclab_tasks/isaaclab_tasks/manager_based/navigation/\
local_planner/local_planner_env_cfg.py
```

### 2. 查看 PPO 配置

```bash
# 神經網路架構和超參數
vim source/isaaclab_tasks/isaaclab_tasks/manager_based/navigation/\
local_planner/agents/rsl_rl_ppo_cfg.py

# 網路架構（第 34-39 行）
sed -n '34,39p' source/isaaclab_tasks/isaaclab_tasks/manager_based/navigation/\
local_planner/agents/rsl_rl_ppo_cfg.py
```

### 3. 查看觀測實現

```bash
# LiDAR 觀測實現
vim +21 source/isaaclab_tasks/isaaclab_tasks/manager_based/navigation/\
local_planner/mdp/observations.py

# 查看所有觀測函數
cat source/isaaclab_tasks/isaaclab_tasks/manager_based/navigation/\
local_planner/mdp/observations.py
```

### 4. 查看獎勵實現

```bash
# 獎勵計算實現
vim source/isaaclab_tasks/isaaclab_tasks/manager_based/navigation/\
local_planner/mdp/rewards.py
```

### 5. 查看訓練腳本

```bash
# 訓練主循環
vim scripts/reinforcement_learning/rsl_rl/train.py
```

### 6. 列出項目結構

```bash
# 查看完整目錄結構
tree -L 3 source/isaaclab_tasks/isaaclab_tasks/manager_based/navigation/local_planner/

# 或使用 ls
ls -R source/isaaclab_tasks/isaaclab_tasks/manager_based/navigation/local_planner/
```

---

## 🐛 常見問題排查

### 1. 檢查環境是否註冊

```bash
./isaaclab.sh -p scripts/tools/list_envs.py | grep -i carter
```

**預期輸出**：
```
Isaac-Navigation-LocalPlanner-Carter-v0
```

### 2. 檢查 Python 環境

```bash
# 確認使用 Isaac Sim Python
./isaaclab.sh -p -c "import sys; print(sys.executable)"

# 應該顯示類似：
# /home/aa/.local/share/ov/pkg/isaac-sim-4.5.0/python.sh
```

### 3. 測試環境能否創建

```bash
./isaaclab.sh -p scripts/tools/check_env.py \
    --task Isaac-Navigation-LocalPlanner-Carter-v0
```

### 4. 檢查 GPU 可用性

```bash
# 檢查 CUDA
./isaaclab.sh -p -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else None}')"
```

### 5. 查看錯誤日誌

```bash
# 如果訓練失敗，檢查最近的日誌
tail -100 logs/rsl_rl/local_planner_carter/[最新目錄]/train.log
```

### 6. 清理殭屍進程

```bash
# 如果遇到 "simulator is already running" 錯誤
killall -r "kit"
killall -r "isaac-sim"

# 等待幾秒後重試訓練
```

### 7. 檢查模型文件

```bash
# 驗證模型文件存在
ls -lh logs/rsl_rl/local_planner_carter/2025-10-23_00-43-53/model_2999.pt

# 檢查模型內容
./isaaclab.sh -p -c "
import torch
checkpoint = torch.load('logs/rsl_rl/local_planner_carter/2025-10-23_00-43-53/model_2999.pt')
print('Keys:', list(checkpoint.keys()))
print('Iteration:', checkpoint.get('iter', 'N/A'))
"
```

---

## 📚 文檔位置

### 主要文檔

```bash
# 訓練架構完整說明（State、Reward、Agent 等）
cat md/訓練架構完整說明.md

# 指令快速參考（本文檔）
cat md/指令快速參考.md

# 項目 README
cat README.md
```

---

## 🎯 快速開始流程

### 完整訓練流程（推薦）⭐

```bash
# 1. 準備環境
cd /home/aa/IsaacLab
conda activate env_isaaclab

# 2. 開始訓練（Headless 模式，48 個環境）
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py \
    --task Isaac-Navigation-LocalPlanner-Carter-v0 \
    --num_envs 48 \
    --headless

# 3. 在另一個終端啟動 TensorBoard 監控
tensorboard --logdir logs/rsl_rl/

# 4. 瀏覽器打開 http://localhost:6006 觀察訓練曲線

# 5. 訓練完成後測試模型
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/play.py \
    --task Isaac-Navigation-LocalPlanner-Carter-v0 \
    --num_envs 1 \
    --checkpoint logs/rsl_rl/local_planner_carter/[最新日期]/model_2999.pt
```

---

## 💡 進階指令

### 1. 自訂訓練參數

```bash
# 修改學習率
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py \
    --task Isaac-Navigation-LocalPlanner-Carter-v0 \
    --num_envs 48 \
    --learning_rate 5e-4

# 修改迭代次數
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py \
    --task Isaac-Navigation-LocalPlanner-Carter-v0 \
    --num_envs 48 \
    --max_iterations 5000
```

### 2. 使用不同演算法（Stable Baselines3）

```bash
./isaaclab.sh -p scripts/reinforcement_learning/sb3/train.py \
    --task Isaac-Navigation-LocalPlanner-Carter-v0 \
    --num_envs 48
```

### 3. 批量測試模型

```bash
# 測試所有保存的檢查點
for model in logs/rsl_rl/local_planner_carter/2025-10-23_00-43-53/model_*.pt; do
    echo "Testing $model"
    ./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/play.py \
        --task Isaac-Navigation-LocalPlanner-Carter-v0 \
        --num_envs 1 \
        --checkpoint "$model" \
        --num_episodes 10
done
```

### 4. 導出模型為 ONNX（部署用）

```bash
./isaaclab.sh -p scripts/tools/export_policy_as_onnx.py \
    --task Isaac-Navigation-LocalPlanner-Carter-v0 \
    --checkpoint logs/rsl_rl/local_planner_carter/2025-10-23_00-43-53/model_2999.pt \
    --output policy.onnx
```

---

## 🔧 Git 版本管理

### 提交訓練結果

```bash
cd /home/aa/IsaacLab

# 添加訓練結果（謹慎：模型文件很大）
git add logs/rsl_rl/local_planner_carter/[日期]/

# 或只提交配置和日誌（推薦）
git add logs/rsl_rl/local_planner_carter/[日期]/params/
git add logs/rsl_rl/local_planner_carter/[日期]/events.out.tfevents.*

# 提交
git commit -m "🎓 訓練完成：3000 次迭代"

# 推送到 GitHub
git push origin main
```

### 提交代碼更改

```bash
# 查看更改
git status

# 添加所有更改
git add -A

# 提交
git commit -m "✨ 更新獎勵函數權重"

# 推送
git push origin main
```

---

## 📞 獲取幫助

### 1. 查看命令幫助

```bash
# 訓練腳本幫助
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py --help

# 測試腳本幫助
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/play.py --help
```

### 2. 列出所有可用環境

```bash
./isaaclab.sh -p scripts/tools/list_envs.py
```

### 3. 查看環境詳情

```bash
./isaaclab.sh -p scripts/tools/check_env.py \
    --task Isaac-Navigation-LocalPlanner-Carter-v0 \
    --verbose
```

---

## 🎯 常用指令速查表

| 操作 | 指令 |
|------|------|
| **訓練（推薦）** | `./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py --task Isaac-Navigation-LocalPlanner-Carter-v0 --num_envs 48 --headless` |
| **測試模型** | `./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/play.py --task Isaac-Navigation-LocalPlanner-Carter-v0 --num_envs 1 --checkpoint logs/rsl_rl/.../model_2999.pt` |
| **查看訓練曲線** | `tensorboard --logdir logs/rsl_rl/` |
| **列出環境** | `./isaaclab.sh -p scripts/tools/list_envs.py` |
| **檢查環境** | `./isaaclab.sh -p scripts/tools/check_env.py --task Isaac-Navigation-LocalPlanner-Carter-v0` |
| **清理進程** | `killall -r "kit"` |
| **查看結果** | `ls -lh logs/rsl_rl/local_planner_carter/` |
| **查看配置** | `cat logs/rsl_rl/.../params/agent.json` |

---

**所有常用指令都在這裡了！** 🚀

複製貼上即可使用，無需記憶複雜參數。

