# 🌍 環境設計詳解

> **Environment Design** - Nova Carter 訓練環境的完整架構

---

## 📋 目錄

1. [場景組成](#場景組成)
2. [環境初始化](#環境初始化)
3. [Episode 流程](#episode-流程)
4. [重置邏輯](#重置邏輯)
5. [終止條件](#終止條件)
6. [物理設置](#物理設置)
7. [並行環境](#並行環境)

---

## 🎬 場景組成

### 場景架構（LocalPlannerSceneCfgMin）

```python
@configclass
class LocalPlannerSceneCfgMin(InteractiveSceneCfg):
    """最小場景：地面 + 機器人 + LiDAR + 目標標記"""
```

---

### 1️⃣ 地面（Terrain）

**類型**：平面地板（Plane）

**配置**：
```python
terrain = TerrainImporterCfg(
    prim_path="/World/ground",
    terrain_type="plane",           # 平面
    terrain_generator=None,         # 不生成複雜地形
    max_init_terrain_level=0,
    collision_group=-1,             # 碰撞組
    physics_material=RigidBodyMaterialCfg(
        friction_combine_mode="multiply",
        restitution_combine_mode="multiply",
        static_friction=1.0,        # 靜摩擦係數
        dynamic_friction=1.0,       # 動摩擦係數
    ),
    debug_vis=False,
)
```

**物理屬性**：
- **大小**：無限大平面
- **高度**：Z = 0
- **摩擦**：高摩擦（防止打滑）
- **彈性**：無彈性
- **碰撞**：啟用（LiDAR 可偵測）

---

### 2️⃣ 機器人（Nova Carter）

**模型**：NVIDIA Nova Carter USD

**配置**：
```python
robot = ArticulationCfg(
    prim_path="{ENV_REGEX_NS}/Robot",  # 每個環境有自己的機器人
    spawn=UsdFileCfg(
        usd_path="/home/aa/isaacsim/usd/nova_carter.usd",
        activate_contact_sensors=False,  # 不啟用接觸感測器
    ),
    init_state=ArticulationCfg.InitialStateCfg(
        pos=(0.0, 0.0, 0.0),            # 初始位置（世界座標）
        rot=(1.0, 0.0, 0.0, 0.0),       # 初始方向（四元數，朝向 +X）
    ),
    actuators={
        "base": ImplicitActuatorCfg(
            joint_names_expr=["joint_wheel_left", "joint_wheel_right"],
            velocity_limit=100.0,        # 速度限制（rad/s）
            effort_limit=1000.0,         # 力矩限制（N·m）
            stiffness=0.0,               # 剛度（速度控制用 0）
            damping=10000.0,             # 阻尼（高阻尼穩定控制）
        ),
    },
)
```

**物理特性**：
- **輪距**：0.413 m
- **輪半徑**：0.125 m
- **質量**：~50 kg（USD 模型定義）
- **驅動**：差速驅動（兩輪獨立控制）
- **控制模式**：速度控制（Velocity Control）

**USD 模型結構**：
```
nova_carter.usd
├── Robot (root)
│   ├── chassis_link (機身)
│   │   ├── base_link (LiDAR 安裝位置)
│   │   ├── lidar_mount
│   │   └── ... (其他鏈接)
│   ├── joint_wheel_left (左輪關節)
│   └── joint_wheel_right (右輪關節)
```

---

### 3️⃣ LiDAR 感測器

**類型**：2D 雷射掃描器（模擬 Velodyne）

**配置**：
```python
lidar = RayCasterCfg(
    prim_path="/World/envs/.*/Robot/Robot/chassis_link/base_link",
    mesh_prim_paths=["/World/ground"],  # 偵測地面
    pattern_cfg=patterns.LidarPatternCfg(
        channels=1,                      # 單層 2D
        vertical_fov_range=(0.0, 0.0),  # 水平掃描
        horizontal_fov_range=(-180.0, 180.0),  # 360° 掃描
        horizontal_res=1.0,              # 每 1° 一條射線
    ),
    max_distance=10.0,                   # 最大探測距離 10m
    drift_range=(0.0, 0.0),             # 無漂移
    debug_vis=False,                     # 不顯示調試線
)
```

**掃描模式**：
```
360° 掃描示意圖：
         0°
         ↑
         |
  90° ←  +  → -90° (270°)
         |
         ↓
       ±180°

射線數量：360 條
掃描頻率：50 Hz（環境控制頻率）
偵測範圍：0.01m ~ 10m
```

**偵測目標**：
- ✅ 地面邊界（如果有）
- ✅ 其他機器人（如果太近）
- ❌ 無其他障礙物（最小場景）

---

### 4️⃣ 光照（Dome Light）

**配置**：
```python
dome_light = AssetBaseCfg(
    prim_path="/World/DomeLight",
    spawn=DomeLightCfg(
        color=(0.9, 0.9, 0.9),  # 白色
        intensity=500.0,         # 亮度
    ),
)
```

**作用**：
- 提供均勻光照
- GUI 模式時可視化
- 不影響訓練（無頭模式無光照）

---

### 5️⃣ 目標標記（Goal Marker）

**可視化**：綠色球體（Debug 模式）

**配置**：
```python
goal_command = UniformPoseCommandCfg(
    asset_name="robot",
    body_name="chassis_link",
    resampling_time_range=(10.0, 10.0),  # 每 10 秒重新生成
    debug_vis=True,                       # 顯示綠色球體
    ranges=Ranges(
        pos_x=(2.0, 6.0),                # X 範圍
        pos_y=(-3.0, 3.0),               # Y 範圍
        pos_z=(0.0, 0.0),                # Z 固定為 0
        roll=(0.0, 0.0),
        pitch=(0.0, 0.0),
        yaw=(0.0, 0.0),
    ),
)
```

**生成邏輯**：
```python
# 隨機生成目標位置（世界座標）
goal_x = robot_x + uniform(2.0, 6.0)  # 前方 2-6m
goal_y = robot_y + uniform(-3.0, 3.0) # 左右 -3-3m
goal_z = 0.0                           # 地面高度
```

---

## 🔄 環境初始化

### 初始化流程

```
1. 創建場景 (Scene Creation)
   ├─ 載入 USD 資產（Nova Carter）
   ├─ 設置物理材質（地面摩擦）
   ├─ 初始化感測器（LiDAR）
   └─ 配置光照

2. 複製環境 (Environment Cloning)
   ├─ 根據 num_envs 創建多個副本
   ├─ 每個環境間隔 env_spacing
   └─ 分配獨立的命名空間

3. 初始化管理器 (Manager Initialization)
   ├─ ObservationManager（觀測）
   ├─ ActionManager（動作）
   ├─ CommandManager（目標）
   ├─ RewardManager（獎勵）
   └─ TerminationManager（終止）

4. 首次重置 (Initial Reset)
   ├─ 機器人回到初始位置
   ├─ 生成首個目標
   └─ 重置所有緩衝區
```

---

### 環境參數

```python
@configclass
class LocalPlannerEnvCfgMin(ManagerBasedRLEnvCfg):
    # 場景設置
    scene = LocalPlannerSceneCfgMin(
        num_envs=24,             # 並行環境數（GPU 訓練）
        env_spacing=10.0,        # 環境間隔 10m
    )
    
    # 時間設置
    decimation = 2               # 控制頻率下採樣
    episode_length_s = 30.0      # Episode 長度 30 秒
    
    # 模擬設置
    sim.dt = 0.01                # 物理時間步 0.01s（100 Hz）
    sim.render_interval = 2      # 渲染間隔（= decimation）
    sim.device = "cuda:0"        # 模擬設備
    
    # 相機設置（GUI 模式）
    viewer.eye = (10.0, 10.0, 10.0)    # 相機位置
    viewer.lookat = (0.0, 0.0, 0.0)    # 觀察點
```

---

### 時間計算

```
物理頻率：1 / dt = 1 / 0.01 = 100 Hz
控制頻率：物理頻率 / decimation = 100 / 2 = 50 Hz
Episode 步數：episode_length_s / (dt × decimation) = 30 / 0.02 = 1500 步

每步時長：dt × decimation = 0.01 × 2 = 0.02s
每秒步數：50 步
```

---

## 🎮 Episode 流程

### 完整 Episode 時序圖

```
Episode 開始（t=0）
  ↓
┌─────────────────────────────────────────┐
│ Reset（重置）                            │
├─────────────────────────────────────────┤
│ 1. 機器人位置 → (0, 0, 0)              │
│ 2. 機器人速度 → (0, 0, 0)              │
│ 3. 生成新目標（隨機位置）                │
│ 4. 重置觀測緩衝                         │
│ 5. 重置獎勵緩衝                         │
└─────────────────────────────────────────┘
  ↓
┌─────────────────────────────────────────┐
│ Step 1 (t = 0.02s)                      │
├─────────────────────────────────────────┤
│ 1. 獲取觀測 → state                     │
│ 2. Agent 決策 → action                  │
│ 3. 執行動作（2 個物理步）                │
│ 4. 計算獎勵 → reward                    │
│ 5. 檢查終止 → done                      │
│ 6. 儲存經驗 (s, a, r, s')              │
└─────────────────────────────────────────┘
  ↓
┌─────────────────────────────────────────┐
│ Step 2 (t = 0.04s)                      │
│ ...                                     │
└─────────────────────────────────────────┘
  ↓
  ... (重複 1500 步或提前終止)
  ↓
┌─────────────────────────────────────────┐
│ Episode 結束                             │
├─────────────────────────────────────────┤
│ 原因：                                  │
│  • 到達目標（done = True）              │
│  • 超時（1500 步，done = True）         │
└─────────────────────────────────────────┘
  ↓
自動 Reset，開始新 Episode
```

---

### 單步執行細節

```python
# env.step(action) 的內部流程

def step(self, action):
    # 1. 動作處理
    self.action_manager.process_action(action)
    # 轉換為輪子速度指令
    
    # 2. 執行物理模擬（decimation 步）
    for _ in range(self.decimation):
        self.sim.step()  # 0.01s 物理步
    # 總共 0.02s
    
    # 3. 更新感測器
    self.scene.update(self.sim.dt * self.decimation)
    # LiDAR 掃描、機器人狀態
    
    # 4. 計算觀測
    obs = self.observation_manager.compute()
    # LiDAR + 速度 + 目標資訊
    
    # 5. 計算獎勵
    reward = self.reward_manager.compute(dt=self.step_dt)
    # 8 項獎勵總和
    
    # 6. 檢查終止
    done = self.termination_manager.compute()
    # 到達目標或超時
    
    # 7. 更新計數器
    self.episode_length_buf += 1
    
    # 8. 自動重置（如果 done）
    if done.any():
        self._reset_idx(done.nonzero())
    
    return obs, reward, done, info
```

---

## 🔄 重置邏輯

### Reset 觸發條件

1. **Episode 開始**：首次調用 `env.reset()`
2. **到達目標**：`goal_reached == True`
3. **超時**：`episode_length >= 1500`
4. **手動重置**：調用 `env.reset()`

---

### Reset 執行流程

```python
def _reset_idx(self, env_ids):
    """重置指定環境"""
    
    # 1. 重置機器人狀態
    self.robot.write_root_pose_to_sim(
        root_pose=default_root_state[env_ids],  # (0, 0, 0)
        env_ids=env_ids,
    )
    self.robot.write_root_velocity_to_sim(
        root_velocity=torch.zeros_like(...),    # 速度歸零
        env_ids=env_ids,
    )
    
    # 2. 重置關節狀態
    self.robot.write_joint_state_to_sim(
        joint_pos=default_joint_pos[env_ids],
        joint_vel=default_joint_vel[env_ids],
        env_ids=env_ids,
    )
    
    # 3. 重新生成目標
    self.command_manager.reset(env_ids=env_ids)
    # 隨機選擇新的目標位置
    
    # 4. 重置管理器緩衝
    self.observation_manager.reset(env_ids=env_ids)
    self.reward_manager.reset(env_ids=env_ids)
    self.termination_manager.reset(env_ids=env_ids)
    
    # 5. 重置 Episode 計數
    self.episode_length_buf[env_ids] = 0
    
    # 6. 清除歷史數據
    if hasattr(self, '_prev_goal_distance'):
        self._prev_goal_distance[env_ids] = ...
```

---

### Reset 後的狀態

```python
機器人：
  位置：(0.0, 0.0, 0.0)
  方向：(1.0, 0.0, 0.0, 0.0)  # 朝向 +X
  速度：(0.0, 0.0, 0.0)
  角速度：(0.0, 0.0, 0.0)

目標：
  位置：random in [(2, -3), (6, 3)]  # 前方 2-6m，左右 -3-3m
  
觀測：
  LiDAR：全 1.0（無障礙物，最遠距離）
  速度：全 0
  目標相對位置：(dx, dy)
  目標距離：||goal - robot||
  
獎勵：
  progress：0（首步無歷史）
  其他：根據初始狀態計算
```

---

## 🏁 終止條件

### 終止檢查（每步執行）

```python
@configclass
class TerminationsCfg:
    # 1. 超時終止
    time_out = DoneTerm(
        func=mdp.time_out,
        time_out=True,  # 標記為超時
    )
    
    # 2. 到達目標終止
    goal_reached = DoneTerm(
        func=mdp.goal_reached,
        params={
            "command_name": "goal_command",
            "threshold": 0.8,  # 0.8m 內算到達
        },
    )
```

---

### 1️⃣ 超時終止（Time Out）

**條件**：
```python
def time_out(env) -> torch.Tensor:
    """檢查是否超時"""
    max_steps = env.max_episode_length  # 1500
    current_steps = env.episode_length_buf
    
    done = (current_steps >= max_steps)
    return done  # shape: (num_envs,)
```

**物理意義**：
- Episode 長度：30 秒（1500 步）
- 如果 30 秒內未到達目標 → 超時
- 超時率高 → Agent 效率低

---

### 2️⃣ 到達目標終止（Goal Reached）

**條件**：
```python
def goal_reached(env, command_name, threshold=0.8) -> torch.Tensor:
    """檢查是否到達目標"""
    command = env.command_manager.get_command(command_name)
    goal_pos_w = command[:, :3]
    
    robot = env.scene["robot"]
    robot_pos_w = robot.data.root_pos_w
    
    # 計算 2D 距離
    distance = torch.norm(
        goal_pos_w[:, :2] - robot_pos_w[:, :2],
        dim=-1
    )
    
    # 距離 < 0.8m 算到達
    done = (distance < threshold)
    return done
```

**物理意義**：
- 目標半徑：0.8m
- 進入 0.8m 內 → 成功
- 同時觸發 `reached_goal` 獎勵（+200）

---

### 終止後的處理

```python
# 在 step() 中

done = self.termination_manager.compute()
# shape: (num_envs,) 布林值

if done.any():
    # 找出需要重置的環境
    env_ids = done.nonzero(as_tuple=False).squeeze(-1)
    
    # 重置這些環境
    self._reset_idx(env_ids)
    
    # 記錄統計數據
    self.extras["time_outs"] = time_out_mask[env_ids]
    self.extras["goal_reached"] = goal_reached_mask[env_ids]
```

---

### 終止統計

**訓練時記錄**：
```python
Episode_Termination/time_out: 0.9583      # 95.83% 超時
Episode_Termination/goal_reached: 0.0417  # 4.17% 成功
```

**理想狀態**：
```python
Episode_Termination/time_out: 0.0         # 0% 超時
Episode_Termination/goal_reached: 1.0     # 100% 成功
```

---

## ⚙️ 物理設置

### PhysX 配置

```python
@configclass
class SimCfg:
    # 時間步
    dt = 0.01                    # 0.01s = 100 Hz
    
    # 渲染
    render_interval = 2          # 每 2 個物理步渲染一次
    
    # PhysX 引擎
    physx = PhysxCfg(
        solver_type=1,           # TGS（Temporal Gauss Seidel）
        min_position_iteration_count=4,
        max_position_iteration_count=255,
        min_velocity_iteration_count=0,
        max_velocity_iteration_count=255,
        enable_ccd=False,        # 連續碰撞偵測（關閉）
        enable_stabilization=True,
        # GPU 管線
        use_gpu=True,
        gpu_max_rigid_contact_count=2**23,
        gpu_max_rigid_patch_count=2**21,
        gpu_found_lost_pairs_capacity=2**21,
        gpu_found_lost_aggregate_pairs_capacity=2**20,
        gpu_total_aggregate_pairs_capacity=2**20,
        gpu_collision_stack_size=2**26,
    )
```

---

### 物理特性

**重力**：
```python
gravity = (0.0, 0.0, -9.81)  # m/s²
```

**摩擦模型**：
```python
# 地面材質
static_friction = 1.0   # 靜摩擦係數
dynamic_friction = 1.0  # 動摩擦係數
friction_combine_mode = "multiply"

# 輪子與地面摩擦
# F_friction = μ × N
# 足夠大防止打滑
```

**碰撞偵測**：
```python
# 當前配置：無碰撞終止
# LiDAR 可偵測障礙物，但碰撞不會終止 Episode
# 未來可加入：
collision_penalty = RewTerm(
    func=mdp.collision_penalty,
    weight=-100.0,
)
```

---

### 數值穩定性

**求解器迭代**：
```python
position_iterations: 4-255  # 位置約束迭代
velocity_iterations: 0-255  # 速度約束迭代

# 更多迭代 = 更穩定但更慢
# 當前設置：允許自適應調整
```

**時間步長**：
```python
dt = 0.01s  # 足夠小以保證穩定性

最大速度：0.8 m/s
最大位移/步：0.8 × 0.01 = 0.008 m = 8 mm
# 遠小於輪半徑（125 mm），穩定
```

---

## 🔢 並行環境

### 環境布局

**24 個環境排列**（6×4 網格）：

```
環境間隔：10m

  Env 0   Env 1   Env 2   Env 3   Env 4   Env 5
   🤖      🤖      🤖      🤖      🤖      🤖
   🟢      🟢      🟢      🟢      🟢      🟢

  Env 6   Env 7   Env 8   Env 9   Env 10  Env 11
   🤖      🤖      🤖      🤖      🤖      🤖
   🟢      🟢      🟢      🟢      🟢      🟢

  Env 12  Env 13  Env 14  Env 15  Env 16  Env 17
   🤖      🤖      🤖      🤖      🤖      🤖
   🟢      🟢      🟢      🟢      🟢      🟢

  Env 18  Env 19  Env 20  Env 21  Env 22  Env 23
   🤖      🤖      🤖      🤖      🤖      🤖
   🟢      🟢      🟢      🟢      🟢      🟢

總場景大小：約 60m × 40m
```

---

### 環境獨立性

**每個環境獨立**：
```python
# 位置偏移
env_origins = torch.tensor([
    [0, 0, 0],      # Env 0
    [10, 0, 0],     # Env 1
    [20, 0, 0],     # Env 2
    ...
], device="cuda")

# 機器人位置 = 環境原點 + 局部位置
robot_pos_w[i] = env_origins[i] + robot_pos_local[i]

# 目標位置 = 環境原點 + 局部目標
goal_pos_w[i] = env_origins[i] + goal_pos_local[i]
```

**不會互相干擾**：
- ✅ 10m 間隔足夠大
- ✅ 目標範圍：前方 2-6m，左右 -3-3m
- ✅ 最大活動範圍：~7m
- ✅ 安全裕度：3m

---

### 並行效率

**數據並行**：
```python
# 所有環境同時執行
obs = torch.stack([env.obs for env in envs])    # (24, 369)
actions = policy(obs)                            # (24, 2)
rewards = torch.stack([env.reward for env in envs])  # (24,)

# GPU 加速
# 24 個環境在單個 forward pass 處理
# 相比單環境快 ~15-20 倍
```

**記憶體使用**：
```python
每個環境：
  - 機器人狀態：~100 KB
  - LiDAR 數據：~10 KB
  - 觀測緩衝：~5 KB
  
24 個環境：~3 MB（狀態數據）
網路參數：~1.5 MB（Actor + Critic）
總 GPU 記憶體：~2 GB（包含 Isaac Sim）
```

---

## 📊 環境統計

### 關鍵指標

```python
# 每次訓練迭代

樣本數：24 envs × 24 steps = 576 samples
訓練時間：~1.5 秒/iter（GPU）
吞吐量：~384 samples/s

# 完整訓練

總迭代：10000 iters
總樣本：10000 × 576 = 5,760,000 samples
訓練時長：10000 × 1.5s ≈ 4.2 小時
```

---

### Episode 統計（目標）

```python
理想狀態：
  - 平均 Episode 長度：~300 步（6 秒）
  - 成功率：>80%
  - 平均獎勵：>50
  - 超時率：<20%

當前狀態（v4 訓練中）：
  - 平均 Episode 長度：1500 步（30 秒）
  - 成功率：~0-5%
  - 平均獎勵：-10 ~ 0
  - 超時率：95-100%
```

---

## 🎯 環境設計特點

### ✅ 優點

1. **簡潔**：最小化場景，聚焦導航任務
2. **高效**：24 並行環境，GPU 加速
3. **穩定**：高摩擦地面，無複雜碰撞
4. **可擴展**：易於加入障礙物、動態物體
5. **可視化**：支持 GUI 模式觀察

### ⚠️ 限制

1. **無障礙物**：只有地面，無真實避障
2. **固定地形**：平面，無複雜地形
3. **無動態**：無移動障礙物
4. **目標簡單**：隨機點，無語義理解

---

## 🔮 未來擴展

### 計劃中的增強

**1. 靜態障礙物**：
```python
obstacles = AssetBaseCfg(
    prim_path="{ENV_REGEX_NS}/Obstacles",
    spawn=UsdFileCfg(
        usd_path="/path/to/obstacles.usd",
    ),
    init_state=AssetInitialStateCfg(
        pos=RandomUniformDistribution(
            min=(-5, -5, 0),
            max=(5, 5, 0),
        ),
    ),
)
```

**2. 動態障礙物**：
```python
dynamic_obstacles = ArticulationCfg(
    # 移動的箱子
    velocity=RandomUniformDistribution(...),
)
```

**3. 複雜地形**：
```python
terrain = TerrainImporterCfg(
    terrain_type="generator",
    terrain_generator=RandomTerrainGeneratorCfg(
        height_range=(0.0, 0.5),  # 高低起伏
        slope_range=(0.0, 0.3),   # 斜坡
    ),
)
```

**4. 課程學習**：
```python
# 逐步增加難度
if iteration < 3000:
    goal_range = (2, 4)    # 近距離
elif iteration < 6000:
    goal_range = (3, 5)    # 中距離
else:
    goal_range = (4, 6)    # 遠距離
```

---

## 📚 總結

### 環境核心設計

```
場景組成：
  ✅ 平面地面（高摩擦）
  ✅ Nova Carter 機器人（差速驅動）
  ✅ 360° LiDAR（10m 範圍）
  ✅ 隨機目標點（2-6m 前方）
  ✅ 24 個並行環境（10m 間隔）

時間設置：
  ✅ 物理頻率：100 Hz（0.01s）
  ✅ 控制頻率：50 Hz（0.02s）
  ✅ Episode 長度：30s（1500 步）

終止條件：
  ✅ 到達目標（< 0.8m）
  ✅ 超時（1500 步）

重置邏輯：
  ✅ 機器人回到原點
  ✅ 速度歸零
  ✅ 重新生成目標
```

---

**查看完整文檔**：
```bash
cat /home/aa/IsaacLab/md/核心文檔/環境設計詳解.md
```

**這份文檔詳細解釋了環境的所有設計細節！** 🌍✨

