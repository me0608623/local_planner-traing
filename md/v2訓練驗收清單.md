# ✅ v2 訓練驗收清單

> **版本**：v2（修正 Reward Hacking）  
> **日期**：2025-10-30  
> **目的**：確認修正是否成功，Agent 是否學會前進

---

## 🎯 v1 失敗回顧

### 實驗結果（10000 iterations）
- ❌ Mean Reward: **190.02**（虛假繁榮）
- ❌ Success Rate: **0%**
- ❌ Timeout Rate: **100%**
- ❌ Position Error: **5.15m**（從未接近）
- ❌ Progress to Goal: **-0.0141**（幾乎不動）
- ✅ Heading Alignment: **4.70**（持續拿分）

### 問題診斷
**Agent 學會「原地朝向目標」策略**：
1. 轉向目標（heading × 5.0 每步累積）
2. 原地不動（避免 progress 負值）
3. 等到超時
4. 結果：高 Reward 但 0% 成功

**典型 Reward Hacking 問題**

---

## 🔧 v2 修正方案

### 1. Heading Alignment 改為條件式
```python
# v1（有漏洞）
heading_alignment:
  - 每步都給分
  - 權重 5.0
  - 無條件累積

# v2（修正）
heading_alignment:
  - 只有「前進（>0.1m/s）+ 朝向正確」才給分
  - 權重 1.0
  - 條件式 gating
```

### 2. 新增反閒置機制
```python
# 三項新增懲罰
anti_idle: -2.0        # 速度 < 0.05 m/s → -1.0
spin_penalty: -0.5     # 原地旋轉 → 負值
time_penalty: -0.02    # 每步成本（30秒累積 -6）
```

### 3. 調整權重平衡
```python
progress_to_goal: 30.0   # ↑ 從 15.0
heading_alignment: 1.0   # ↓ 從 5.0
standstill: 4.0          # ↑ 從 2.0
```

### 4. 修復符號問題
```python
# standstill_penalty 明確返回負值
return -torch.exp(-10.0 * speed)
```

---

## 📊 v2 驗收標準（6 條關鍵曲線）

### ✅ 必須改善的指標

#### 1. Episode_Reward/progress_to_goal
**v1 結果**：-0.0141（幾乎為 0）  
**v2 目標**：**明顯 > 0**（平均 > 0.5）  
**含義**：Agent 開始前進接近目標

**檢查方法**：
- TensorBoard → SCALARS → Episode_Reward/progress_to_goal
- 曲線應該從 0 附近逐步上升
- 1000 iter 後平均應 > 0.2
- 3000 iter 後平均應 > 0.5

---

#### 2. Episode_Reward/heading_alignment
**v1 結果**：4.70（持續高值，問題來源）  
**v2 目標**：**下降但仍為正**（平均 0.5-1.5）  
**含義**：Agent 在前進時也保持朝向，但不再是主要獎勵來源

**檢查方法**：
- 曲線應該比 v1 明顯降低
- 不應該再是 Mean Reward 的主要來源
- 如果仍然 >3.0 → 條件式 gating 可能未生效

---

#### 3. Episode_Reward/standstill_penalty
**v1 結果**：1.9039（正值，符號錯誤）  
**v2 目標**：**明顯為負值**（平均 < -0.5）  
**含義**：懲罰正確施加，Agent 被迫移動

**檢查方法**：
- 必須為負值（如果為正值，函數實現仍有問題）
- 絕對值應隨訓練逐步降低（Agent 學會移動）
- 配合 anti_idle 和 time_penalty 一起觀察

---

#### 4. Episode_Termination/time_out
**v1 結果**：1.0000（100%，全部超時）  
**v2 目標**：**< 0.8**（3000 iter），**< 0.6**（5000 iter）  
**含義**：Agent 開始能夠到達目標或碰撞（而非只會等待）

**檢查方法**：
- 曲線應該逐步下降
- 如果持續 >90% → Agent 仍然不會前進
- 目標：5000 iter 後降到 60% 以下

---

#### 5. Episode_Termination/goal_reached
**v1 結果**：0.0000（0%，完全失敗）  
**v2 目標**：**> 0%**（看到成功事件）  
**含義**：Agent 至少偶爾能到達目標

**檢查方法**：
- 早期（1000 iter）：可能仍是 0%（正常）
- 中期（3000 iter）：應該 >1%（開始出現成功）
- 後期（5000 iter）：應該 >5%（穩定成功）
- 如果始終 0% → 需要更激進的調整

---

#### 6. Metrics/goal_command/position_error
**v1 結果**：5.15m（從未接近）  
**v2 目標**：**先破 3m，再逼近 1.5m**  
**含義**：Agent 實際能夠靠近目標

**檢查方法**：
- 1000 iter：從 5m → 4m
- 3000 iter：從 4m → 3m
- 5000 iter：從 3m → 2m
- 最終目標：< 1.5m

---

## 🚨 故障排除

### 如果 progress_to_goal 仍然為 0

**原因**：Agent 仍然不動  
**解決**：
1. 進一步提升 standstill 權重到 10.0
2. 提升 anti_idle 權重到 5.0
3. 提升 time_penalty 權重到 0.05

### 如果 heading_alignment 仍然很高（>3.0）

**原因**：條件式 gating 未生效  
**解決**：
1. 檢查 `v_min` 參數是否傳入
2. 提高 `v_min` 到 0.2 m/s
3. 或直接移除 heading_alignment

### 如果 standstill_penalty 仍為正值

**原因**：函數實現或權重符號問題  
**解決**：
1. 檢查 `rewards.py` 第 180-204 行
2. 確認返回值為 `-torch.exp(-10.0 * speed)`
3. 確認 env_cfg_min.py 中 weight 為正數（4.0）

### 如果出現原地抖動

**原因**：`init_noise_std` 仍然過高  
**解決**：
```python
# rsl_rl_ppo_cfg.py
init_noise_std: 0.5 → 0.3
```

---

## 🎯 v2 訓練配置總結

### 獎勵權重（8 項）
```python
progress_to_goal: 30.0        # 主要驅動力
near_goal_shaping: 10.0       # 近距離塑形
heading_alignment: 1.0        # 輔助（條件式）
reached_goal: 200.0           # 成功大獎
standstill: 4.0               # 反靜止（函數返回負值）
anti_idle: 2.0                # 反閒置（函數返回負值）
spin_penalty: 0.5             # 反旋轉（函數返回負值）
time_penalty: 0.02            # 時間成本（每步 -0.02）
```

### PPO 參數（穩定版）
```python
entropy_coef: 0.001           # 穩定
clip_param: 0.1               # 穩定
num_learning_epochs: 3        # 穩定
learning_rate: 3e-4           # 穩定
init_noise_std: 0.5           # 如有抖動 → 0.3
```

### 訓練參數
```bash
--task Isaac-Navigation-LocalPlanner-Min-v0
--num_envs 24
--max_iterations 5000
--headless
```

---

## 📈 成功指標（同時滿足才算成功）

| 指標 | v1 失敗值 | v2 目標值 | 權重 |
|------|----------|----------|------|
| **Progress to Goal** | -0.01 | **> 0.5** | ⭐⭐⭐ |
| **Position Error** | 5.15m | **< 3.0m** | ⭐⭐⭐ |
| **Timeout Rate** | 100% | **< 80%** | ⭐⭐⭐ |
| **Success Rate** | 0% | **> 0%** | ⭐⭐ |
| **Heading Alignment** | 4.70 | **< 2.0** | ⭐ |
| **Standstill Penalty** | +1.90 | **< -0.5** | ⭐⭐ |

**核心判斷**：
- 如果 **Progress > 0** + **Position Error 下降** + **Standstill < 0**
  → ✅ 修正成功，Agent 開始前進

- 如果 **Progress 仍為 0** + **Position Error 停滯**
  → ❌ 需要更激進調整

---

## 💡 下一步行動

### 立即啟動 v2 訓練

```bash
cd /home/aa/IsaacLab

./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py \
    --task Isaac-Navigation-LocalPlanner-Min-v0 \
    --num_envs 24 \
    --max_iterations 5000 \
    --headless
```

### 同時啟動 TensorBoard 監控

```bash
# 在另一個終端
cd /home/aa/IsaacLab
tensorboard --logdir logs/rsl_rl/local_planner_carter/
```

**瀏覽器**：http://localhost:6006

**重點監控**：上述 6 條關鍵曲線

### 檢查點（訓練中途評估）

- **1000 iter**：檢查 progress 是否 > 0
- **3000 iter**：檢查 position_error 是否 < 4m
- **5000 iter**：檢查 success_rate 是否 > 0%

**如果 1000 iter 時 progress 仍為 0 → 立即停止，進一步調整**

---

**v2 訓練準備完成！等待啟動指令。** 🚀

