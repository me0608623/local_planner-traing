# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
# All rights reserved.
#
# SPDX-License-Identifier: BSD-3-Clause

"""RSL-RL PPO æ¼”ç®—æ³•é…ç½® - æœ¬åœ°è¦åŠƒå™¨ä»»å‹™"""

from isaaclab.utils import configclass
from isaaclab_rl.rsl_rl import RslRlOnPolicyRunnerCfg, RslRlPpoActorCriticCfg, RslRlPpoAlgorithmCfg


@configclass
class LocalPlannerPPORunnerCfg(RslRlOnPolicyRunnerCfg):
    """RSL-RL PPO Runner é…ç½® - Nova Carter æœ¬åœ°è¦åŠƒå™¨
    
    æ¡ç”¨èˆ‡å…¶ä»– Isaac Lab ä»»å‹™ä¸€è‡´çš„ç°¡æ½”é…ç½®é¢¨æ ¼ã€‚
    RSL-RL æœƒè‡ªå‹•è™•ç†è§€æ¸¬åˆ†çµ„ï¼Œç„¡éœ€æ‰‹å‹•é…ç½® obs_groupsã€‚
    """

    # åŸºæœ¬é…ç½®
    seed: int = 42
    device: str = "cuda:0"
    num_steps_per_env: int = 24
    max_iterations: int = 3000
    save_interval: int = 100
    experiment_name: str = "local_planner_carter"
    run_name: str = ""  # é‹è¡Œåç¨±ï¼Œæœƒé™„åŠ åœ¨æ—¥èªŒç›®éŒ„å¾Œ
    empirical_normalization: bool = False
    
    # è§€æ¸¬çµ„é…ç½® - è¨­ç‚º None è®“ RSL-RL è‡ªå‹•æ¨æ–·
    obs_groups: dict | None = None
    
    # ç¶²è·¯æ¶æ§‹é…ç½®
    policy = RslRlPpoActorCriticCfg(
        init_noise_std=0.5,
        actor_hidden_dims=[256, 256, 128],
        critic_hidden_dims=[256, 256, 128],
        activation="elu",
    )
    
    # PPO æ¼”ç®—æ³•è¶…åƒæ•¸
    algorithm = RslRlPpoAlgorithmCfg(
        value_loss_coef=1.0,
        use_clipped_value_loss=True,
        clip_param=0.1,
        entropy_coef=0.001,
        num_learning_epochs=3,
        num_mini_batches=4,
        learning_rate=3e-4,  # ğŸ”§ å¾1e-3é™åˆ°3e-4ï¼ˆ0.0003ï¼‰ï¼Œæå‡ç©©å®šæ€§
        schedule="adaptive",
        gamma=0.99,
        lam=0.95,
        desired_kl=0.01,
        max_grad_norm=1.0,
    )

