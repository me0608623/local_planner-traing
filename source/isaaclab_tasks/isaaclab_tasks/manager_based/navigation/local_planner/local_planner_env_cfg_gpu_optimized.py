# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
# All rights reserved.
#
# SPDX-License-Identifier: BSD-3-Clause

"""
Nova Carter æœ¬åœ°è¦åŠƒå™¨ GPU æ·±åº¦å„ªåŒ–é…ç½®
å¯¦æ–½è·¯ç·šAï¼šå…¨ç¨‹GPUï¼ˆæœ€å„ªé›…çš„è§£æ±ºæ–¹æ¡ˆï¼‰
"""

import torch
# Isaac Sim 5.0 å…¼å®¹æ€§å°å…¥
try:
    from isaacsim.core.api.utils.torch import set_cuda_device
    print("âœ… [Isaac Sim 5.0] ä½¿ç”¨æ–°ç‰ˆæ¨¡çµ„ isaacsim.core.api.utils.torch")
except ImportError:
    try:
        from omni.isaac.core.utils.torch import set_cuda_device
        print("âš ï¸ [Isaac Sim 5.0] å›é€€åˆ°èˆŠç‰ˆæ¨¡çµ„ omni.isaac.core.utils.torch")
    except ImportError:
        print("âŒ [Isaac Sim 5.0] ç„¡æ³•å°å…¥ Isaac Sim ç›¸é—œæ¨¡çµ„ï¼Œä½¿ç”¨ç´” PyTorch æ›¿ä»£æ–¹æ¡ˆ")
        def set_cuda_device(device: int):
            import torch
            if torch.cuda.is_available():
                torch.cuda.set_device(device)
            else:
                print("CUDA ä¸å¯ç”¨ï¼Œç„¡æ³•è¨­å®šè¨­å‚™ã€‚")
import isaaclab.sim as sim_utils
from isaaclab.utils import configclass

from .local_planner_env_cfg import LocalPlannerEnvCfg, LocalPlannerEnvCfg_SIMPLE

##
# GPU å…¨ç¨‹å„ªåŒ–ç’°å¢ƒé…ç½®
##

@configclass 
class LocalPlannerEnvCfg_GPU_OPTIMIZED(LocalPlannerEnvCfg):
    """Nova Carter æœ¬åœ°è¦åŠƒå™¨ - GPU æ·±åº¦å„ªåŒ–ç‰ˆæœ¬
    
    è·¯ç·šAï¼šå…¨ç¨‹GPUï¼ˆå»ºè­°ï¼‰
    æ ¸å¿ƒç­–ç•¥ï¼šç¢ºä¿æ‰€æœ‰èˆ‡PhysX tensors APIäº¤äº’çš„æ•¸æ“šéƒ½æ˜¯CUDA tensor
    
    è§£æ±ºæ ¹æœ¬å•é¡Œï¼š
    - ä¸è¿´é¿å•é¡Œï¼Œè€Œæ˜¯ç¢ºä¿è¨­å‚™ä¸€è‡´æ€§
    - æ‰€æœ‰å‚³çµ¦PhysX/Isaac APIçš„æ•¸æ“šéƒ½æ˜¯CUDA tensor
    - é å…ˆè¨­å®šIsaac/Torchçš„é è¨­è£ç½®
    - ç¢ºä¿æ²’æœ‰CPU Tensoræ„å¤–æ··å…¥
    """
    
    def __post_init__(self):
        """å¾Œè™•ç†ï¼šGPU æ·±åº¦å„ªåŒ–è¨­å®š"""
        # ğŸ”§ ç¬¬ä¸€æ­¥ï¼šé å…ˆè¨­å®šè¨­å‚™ï¼ˆåœ¨ä»»ä½•å…¶ä»–æ“ä½œä¹‹å‰ï¼‰
        device_id = 0  # ä½¿ç”¨ GPU 0
        
        # è¨­å®š Isaac Core çš„é è¨­è£ç½®
        set_cuda_device(device_id)
        print(f"ğŸ”§ [GPUå„ªåŒ–] Isaac Core è¨­å‚™è¨­å®š: cuda:{device_id}")
        
        # è¨­å®š PyTorch çš„é è¨­è£ç½®
        torch.cuda.set_device(device_id)
        device = torch.device(f"cuda:{device_id}")
        torch.set_default_tensor_type("torch.cuda.FloatTensor")
        print(f"ğŸ”§ [GPUå„ªåŒ–] PyTorch é è¨­è¨­å‚™: {device}")
        
        # èª¿ç”¨çˆ¶é¡è¨­å®š
        super().__post_init__()
        
        # ğŸ”§ ç¬¬äºŒæ­¥ï¼šå¼·åŒ– GPU è¨­å®šï¼ˆè¦†è“‹ä»»ä½•å¯èƒ½çš„ CPU å›é€€ï¼‰
        self.sim.device = f"cuda:{device_id}"
        
        # ç¢ºä¿ PhysX å®Œå…¨ä½¿ç”¨ GPU
        self.sim.physx.use_gpu = True
        self.sim.physx.gpu_device_id = device_id
        
        # ğŸ”§ ç¬¬ä¸‰æ­¥ï¼šå¤§å¹…å¢åŠ  GPU ç·©è¡å€å®¹é‡ï¼ˆé˜²æ­¢è¨˜æ†¶é«”ä¸è¶³å°è‡´å›é€€åˆ°CPUï¼‰
        # æ¯”ä¹‹å‰çš„è¨­å®šæ›´å¤§ï¼Œç¢ºä¿ä¸æœƒå› è¨˜æ†¶é«”ä¸è¶³è€Œè‡ªå‹•åˆ‡æ›åˆ°CPU
        self.sim.physx.gpu_max_rigid_contact_count = 2048 * 1024    # 2M contacts
        self.sim.physx.gpu_max_rigid_patch_count = 1024 * 1024     # 1M patches
        self.sim.physx.gpu_found_lost_pairs_capacity = 2048 * 1024 # 2M pairs
        self.sim.physx.gpu_found_lost_aggregate_pairs_capacity = 512 * 1024  # 512K
        self.sim.physx.gpu_total_aggregate_pairs_capacity = 2048 * 1024      # 2M
        
        # ğŸ”§ ç¬¬å››æ­¥ï¼šå•Ÿç”¨é€²éš GPU å„ªåŒ–
        self.sim.physx.enable_ccd = True  # é€£çºŒç¢°æ’æª¢æ¸¬
        self.sim.physx.enable_stabilization = True  # ç‰©ç†ç©©å®šåŒ–
        self.sim.physx.use_gpu_pipeline = True  # å¼·åˆ¶ä½¿ç”¨ GPU pipeline
        
        # ğŸ”§ ç¬¬äº”æ­¥ï¼šå„ªåŒ–ç’°å¢ƒæ•¸é‡ä»¥å……åˆ†åˆ©ç”¨ GPU
        # ä½¿ç”¨æ›´å¤šç’°å¢ƒä¾†å……åˆ†åˆ©ç”¨ GPU ä¸¦è¡Œèƒ½åŠ›
        original_num_envs = self.scene.num_envs
        self.scene.num_envs = min(original_num_envs, 512)  # æœ€å¤š512å€‹ç’°å¢ƒï¼Œå¹³è¡¡æ€§èƒ½å’Œè¨˜æ†¶é«”
        
        # å„ªåŒ–æ™‚é–“æ­¥é•·è¨­å®š
        self.decimation = 4   # ä¿æŒåŸå§‹è¨­å®šä»¥ç¢ºä¿ç©©å®šæ€§
        self.sim.dt = 0.01    # ä¿æŒé«˜ç²¾åº¦æ™‚é–“æ­¥é•·
        
        print("ğŸ”§ [GPUæ·±åº¦å„ªåŒ–] é…ç½®å®Œæˆ")
        print(f"   - è¨­å‚™æ¨¡å¼: {self.sim.device}")
        print(f"   - PhysX GPU: {self.sim.physx.use_gpu}")
        print(f"   - GPU è¨­å‚™ID: {self.sim.physx.gpu_device_id}")
        print(f"   - ç’°å¢ƒæ•¸é‡: {self.scene.num_envs} (åŸå§‹: {original_num_envs})")
        print(f"   - GPU ç·©è¡å€: {self.sim.physx.gpu_max_rigid_contact_count // 1024}K contacts")
        print(f"   - PyTorch é è¨­è¨­å‚™: {torch.get_default_device()}")


@configclass
class LocalPlannerEnvCfg_GPU_OPTIMIZED_SIMPLE(LocalPlannerEnvCfg_SIMPLE):
    """GPU æ·±åº¦å„ªåŒ–ç°¡åŒ–ç‰ˆæœ¬ - ç”¨æ–¼æ¸¬è©¦å’Œé©—è­‰"""
    
    def __post_init__(self):
        """å¾Œè™•ç†ï¼šGPU å„ªåŒ– + ç°¡åŒ–è¨­å®š"""
        # è¨­å®šè¨­å‚™
        device_id = 0
        set_cuda_device(device_id)
        torch.cuda.set_device(device_id)
        torch.set_default_tensor_type("torch.cuda.FloatTensor")
        
        # èª¿ç”¨çˆ¶é¡è¨­å®š
        super().__post_init__()
        
        # GPU å„ªåŒ–è¨­å®š
        self.sim.device = f"cuda:{device_id}"
        self.sim.physx.use_gpu = True
        self.sim.physx.gpu_device_id = device_id
        
        # é©ä¸­çš„ç·©è¡å€è¨­å®šï¼ˆæ¸¬è©¦ç”¨ï¼‰
        self.sim.physx.gpu_max_rigid_contact_count = 1024 * 1024    
        self.sim.physx.gpu_max_rigid_patch_count = 512 * 1024     
        self.sim.physx.gpu_found_lost_pairs_capacity = 1024 * 1024 
        
        # æ¸¬è©¦å‹å¥½çš„ç’°å¢ƒæ•¸é‡
        self.scene.num_envs = 32   # é©ä¸­æ•¸é‡ä¾¿æ–¼æ¸¬è©¦
        self.episode_length_s = 20.0  # è¼ƒçŸ­å›åˆä¾¿æ–¼å¿«é€Ÿæ¸¬è©¦
        
        print("ğŸ”§ [GPUæ·±åº¦å„ªåŒ–-ç°¡åŒ–] é…ç½®å®Œæˆ")
        print(f"   - è¨­å‚™æ¨¡å¼: {self.sim.device}")
        print(f"   - ç’°å¢ƒæ•¸é‡: {self.scene.num_envs}")
        print(f"   - å›åˆé•·åº¦: {self.episode_length_s}s")


##
# å¼µé‡è¨­å‚™å·¥å…·å‡½æ•¸
##

def ensure_cuda_tensor(data, device_id: int = 0):
    """ç¢ºä¿æ•¸æ“šæ˜¯ CUDA tensor
    
    ç”¨æ–¼èˆ‡ PhysX/Isaac API äº¤äº’çš„æ‰€æœ‰æ•¸æ“š
    
    Args:
        data: è¼¸å…¥æ•¸æ“š (numpy array, CPU tensor, æˆ–å·²ç¶“æ˜¯ CUDA tensor)
        device_id: CUDA è¨­å‚™ ID
    
    Returns:
        CUDA tensor
    """
    device = torch.device(f"cuda:{device_id}")
    
    if isinstance(data, torch.Tensor):
        return data.to(device, dtype=torch.float32)
    else:
        # numpy array æˆ–å…¶ä»–æ ¼å¼
        return torch.tensor(data, dtype=torch.float32, device=device)


def convert_positions_to_cuda(coords, orientations=None, device_id: int = 0):
    """å°‡ä½ç½®å’Œæ–¹å‘æ•¸æ“šè½‰æ›ç‚º CUDA tensor
    
    å°ˆé–€ç”¨æ–¼ set_world_poses() ç­‰ PhysX API èª¿ç”¨
    
    Args:
        coords: ä½ç½®åº§æ¨™ (N, 3) æˆ– (3,)
        orientations: å››å…ƒæ•¸æ–¹å‘ (N, 4) æˆ– (4,)ï¼Œå¦‚æœç‚º None å‰‡ä½¿ç”¨é è¨­æ–¹å‘
        device_id: CUDA è¨­å‚™ ID
    
    Returns:
        tuple: (cuda_coords, cuda_orientations)
    """
    device = torch.device(f"cuda:{device_id}")
    
    # è½‰æ›ä½ç½®
    if isinstance(coords, (list, tuple)):
        coords = torch.tensor(coords, dtype=torch.float32, device=device)
    elif isinstance(coords, torch.Tensor):
        coords = coords.to(device, dtype=torch.float32)
    else:
        # numpy array
        coords = torch.tensor(coords, dtype=torch.float32, device=device)
    
    # ç¢ºä¿æ˜¯ 2D tensor (N, 3)
    if coords.dim() == 1:
        coords = coords.unsqueeze(0)
    
    # è½‰æ›æ–¹å‘
    if orientations is None:
        # é è¨­æ–¹å‘ (ç„¡æ—‹è½‰): [0, 0, 0, 1]
        batch_size = coords.shape[0]
        orientations = torch.tensor([0.0, 0.0, 0.0, 1.0], device=device).repeat(batch_size, 1)
    else:
        if isinstance(orientations, (list, tuple)):
            orientations = torch.tensor(orientations, dtype=torch.float32, device=device)
        elif isinstance(orientations, torch.Tensor):
            orientations = orientations.to(device, dtype=torch.float32)
        else:
            # numpy array
            orientations = torch.tensor(orientations, dtype=torch.float32, device=device)
        
        # ç¢ºä¿æ˜¯ 2D tensor (N, 4)
        if orientations.dim() == 1:
            orientations = orientations.unsqueeze(0)
    
    return coords, orientations


##
# ä½¿ç”¨ç¯„ä¾‹å’Œæœ€ä½³å¯¦è¸
##

class GPUOptimizedUsageExample:
    """GPU å„ªåŒ–ä½¿ç”¨ç¯„ä¾‹"""
    
    @staticmethod
    def example_set_world_poses():
        """æ­£ç¢ºçš„ set_world_poses ä½¿ç”¨æ–¹å¼"""
        # âŒ éŒ¯èª¤ï¼šä½¿ç”¨ numpy arrayï¼ˆæœƒå°è‡´å¼µé‡è¨­å‚™ä¸åŒ¹é…ï¼‰
        # coords_np = np.array([[-8.0, 32.0, -2.3]])
        # orient_np = np.array([[0.0, 0.0, 0.0, 1.0]]) 
        # self.cube_xform1.set_world_poses(coords_np, orient_np)  # é€™æœƒå‡ºéŒ¯ï¼
        
        # âœ… æ­£ç¢ºï¼šä½¿ç”¨ CUDA tensor
        coords, orient = convert_positions_to_cuda(
            coords=[[-8.0, 32.0, -2.3]], 
            orientations=[[0.0, 0.0, 0.0, 1.0]],
            device_id=0
        )
        # self.cube_xform1.set_world_poses(coords, orient)  # é€™æ˜¯æ­£ç¢ºçš„ï¼
        
    @staticmethod
    def example_data_conversion():
        """æ•¸æ“šè½‰æ›ç¯„ä¾‹"""
        # å¾ PhysX API è®€å–çš„ CUDA tensor
        # cuda_positions = articulation_view.get_world_poses()
        
        # å¦‚æœéœ€è¦èˆ‡ numpy/ROS äº¤äº’ï¼Œè½‰åˆ° CPU
        # cpu_positions = cuda_positions.cpu().numpy()
        
        # ROS è¨Šæ¯è™•ç†ï¼ˆCPU æ²’é—œä¿‚ï¼‰
        # ros_msg.data = cpu_positions.flatten().tolist()
        
        # å†æ¬¡èˆ‡ PhysX äº¤äº’æ™‚ï¼Œè½‰å› CUDA
        # cuda_new_positions = ensure_cuda_tensor(cpu_positions, device_id=0)
        pass
