# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
# All rights reserved.
#
# SPDX-License-Identifier: BSD-3-Clause

"""
Nova Carter æœ¬åœ°è¦åŠƒå™¨ GPU æ·±åº¦å„ªåŒ–é…ç½® (ä¿®å¾©ç‰ˆ)
å¯¦æ–½è·¯ç·šAï¼šå…¨ç¨‹GPUï¼Œä½†ä¸ä¾è³´ omni.isaac.core.utils.torch
"""

import torch
import isaaclab.sim as sim_utils
from isaaclab.utils import configclass

from .local_planner_env_cfg import LocalPlannerEnvCfg, LocalPlannerEnvCfg_SIMPLE

##
# GPU å…¨ç¨‹å„ªåŒ–ç’°å¢ƒé…ç½® (ä¿®å¾©ç‰ˆ)
##

@configclass 
class LocalPlannerEnvCfg_GPU_OPTIMIZED_FIXED(LocalPlannerEnvCfg):
    """Nova Carter æœ¬åœ°è¦åŠƒå™¨ - GPU æ·±åº¦å„ªåŒ–ç‰ˆæœ¬ (ä¿®å¾©ç‰ˆ)
    
    è·¯ç·šAï¼šå…¨ç¨‹GPUï¼ˆå»ºè­°ï¼‰
    æ ¸å¿ƒç­–ç•¥ï¼šç¢ºä¿æ‰€æœ‰èˆ‡PhysX tensors APIäº¤äº’çš„æ•¸æ“šéƒ½æ˜¯CUDA tensor
    
    ä¿®å¾©ç‰ˆæœ¬ï¼š
    - ä¸ä¾è³´ omni.isaac.core.utils.torchï¼ˆè§£æ±ºå°å…¥å•é¡Œï¼‰
    - ç›´æ¥ä½¿ç”¨ PyTorch çš„è¨­å‚™ç®¡ç†
    - ä¿æŒGPUå„ªåŒ–çš„æ ¸å¿ƒç†å¿µ
    """
    
    def __post_init__(self):
        """å¾Œè™•ç†ï¼šGPU æ·±åº¦å„ªåŒ–è¨­å®š (ä¿®å¾©ç‰ˆ)"""
        # ğŸ”§ ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨ PyTorch ç›´æ¥è¨­å®šè¨­å‚™ï¼ˆä¸ä¾è³´ omni.isaac.coreï¼‰
        device_id = 0  # ä½¿ç”¨ GPU 0
        
        # è¨­å®š PyTorch çš„é è¨­è£ç½®
        if torch.cuda.is_available():
            torch.cuda.set_device(device_id)
            device = torch.device(f"cuda:{device_id}")
            # è¨­å®šé è¨­å¼µé‡é¡å‹ç‚º CUDA
            torch.set_default_dtype(torch.float32)
            # å°‡é è¨­è¨­å‚™è¨­ç‚º CUDAï¼ˆå¦‚æœæ”¯æ´ï¼‰
            if hasattr(torch, 'set_default_device'):
                torch.set_default_device(device)
            print(f"ğŸ”§ [GPUå„ªåŒ–-ä¿®å¾©ç‰ˆ] PyTorch è¨­å‚™è¨­å®š: {device}")
        else:
            print("âš ï¸ [è­¦å‘Š] CUDA ä¸å¯ç”¨ï¼Œä½¿ç”¨ CPU")
            device_id = None
        
        # èª¿ç”¨çˆ¶é¡è¨­å®š
        super().__post_init__()
        
        # ğŸ”§ ç¬¬äºŒæ­¥ï¼šå¼·åŒ– GPU è¨­å®šï¼ˆåƒ…åœ¨ CUDA å¯ç”¨æ™‚ï¼‰
        if torch.cuda.is_available():
            self.sim.device = f"cuda:{device_id}"
            
            # ç¢ºä¿ PhysX å®Œå…¨ä½¿ç”¨ GPU
            self.sim.physx.use_gpu = True
            if hasattr(self.sim.physx, 'gpu_device_id'):
                self.sim.physx.gpu_device_id = device_id
            
            # ğŸ”§ ç¬¬ä¸‰æ­¥ï¼šå¤§å¹…å¢åŠ  GPU ç·©è¡å€å®¹é‡
            self.sim.physx.gpu_max_rigid_contact_count = 2048 * 1024    # 2M contacts
            self.sim.physx.gpu_max_rigid_patch_count = 1024 * 1024     # 1M patches
            self.sim.physx.gpu_found_lost_pairs_capacity = 2048 * 1024 # 2M pairs
            self.sim.physx.gpu_found_lost_aggregate_pairs_capacity = 512 * 1024  # 512K
            self.sim.physx.gpu_total_aggregate_pairs_capacity = 2048 * 1024      # 2M
            
            # ğŸ”§ ç¬¬å››æ­¥ï¼šå•Ÿç”¨é€²éš GPU å„ªåŒ–
            self.sim.physx.enable_ccd = True  # é€£çºŒç¢°æ’æª¢æ¸¬
            self.sim.physx.enable_stabilization = True  # ç‰©ç†ç©©å®šåŒ–
            if hasattr(self.sim.physx, 'use_gpu_pipeline'):
                self.sim.physx.use_gpu_pipeline = True  # å¼·åˆ¶ä½¿ç”¨ GPU pipeline
            
            # ğŸ”§ ç¬¬äº”æ­¥ï¼šå„ªåŒ–ç’°å¢ƒæ•¸é‡
            original_num_envs = self.scene.num_envs
            self.scene.num_envs = min(original_num_envs, 512)  # æœ€å¤š512å€‹ç’°å¢ƒ
            
            print("ğŸ”§ [GPUæ·±åº¦å„ªåŒ–-ä¿®å¾©ç‰ˆ] é…ç½®å®Œæˆ")
            print(f"   - è¨­å‚™æ¨¡å¼: {self.sim.device}")
            print(f"   - PhysX GPU: {self.sim.physx.use_gpu}")
            print(f"   - ç’°å¢ƒæ•¸é‡: {self.scene.num_envs} (åŸå§‹: {original_num_envs})")
            print(f"   - GPU ç·©è¡å€: {self.sim.physx.gpu_max_rigid_contact_count // 1024}K contacts")
            print(f"   - PyTorch CUDA å¯ç”¨: {torch.cuda.is_available()}")
        else:
            print("ğŸ”§ [GPUæ·±åº¦å„ªåŒ–-ä¿®å¾©ç‰ˆ] CUDA ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨™æº–é…ç½®")


@configclass
class LocalPlannerEnvCfg_GPU_OPTIMIZED_SIMPLE_FIXED(LocalPlannerEnvCfg_SIMPLE):
    """GPU æ·±åº¦å„ªåŒ–ç°¡åŒ–ç‰ˆæœ¬ (ä¿®å¾©ç‰ˆ) - ç”¨æ–¼æ¸¬è©¦å’Œé©—è­‰"""
    
    def __post_init__(self):
        """å¾Œè™•ç†ï¼šGPU å„ªåŒ– + ç°¡åŒ–è¨­å®š (ä¿®å¾©ç‰ˆ)"""
        # ä½¿ç”¨ PyTorch ç›´æ¥è¨­å®šè¨­å‚™
        device_id = 0
        if torch.cuda.is_available():
            torch.cuda.set_device(device_id)
            torch.set_default_dtype(torch.float32)
            if hasattr(torch, 'set_default_device'):
                torch.set_default_device(f"cuda:{device_id}")
        
        # èª¿ç”¨çˆ¶é¡è¨­å®š
        super().__post_init__()
        
        # GPU å„ªåŒ–è¨­å®š
        if torch.cuda.is_available():
            self.sim.device = f"cuda:{device_id}"
            self.sim.physx.use_gpu = True
            if hasattr(self.sim.physx, 'gpu_device_id'):
                self.sim.physx.gpu_device_id = device_id
            
            # é©ä¸­çš„ç·©è¡å€è¨­å®šï¼ˆæ¸¬è©¦ç”¨ï¼‰
            self.sim.physx.gpu_max_rigid_contact_count = 1024 * 1024    
            self.sim.physx.gpu_max_rigid_patch_count = 512 * 1024     
            self.sim.physx.gpu_found_lost_pairs_capacity = 1024 * 1024 
            
            # æ¸¬è©¦å‹å¥½çš„ç’°å¢ƒæ•¸é‡
            self.scene.num_envs = 32   # é©ä¸­æ•¸é‡ä¾¿æ–¼æ¸¬è©¦
            self.episode_length_s = 20.0  # è¼ƒçŸ­å›åˆä¾¿æ–¼å¿«é€Ÿæ¸¬è©¦
            
            print("ğŸ”§ [GPUæ·±åº¦å„ªåŒ–-ç°¡åŒ–-ä¿®å¾©ç‰ˆ] é…ç½®å®Œæˆ")
            print(f"   - è¨­å‚™æ¨¡å¼: {self.sim.device}")
            print(f"   - ç’°å¢ƒæ•¸é‡: {self.scene.num_envs}")
            print(f"   - å›åˆé•·åº¦: {self.episode_length_s}s")


##
# å¼µé‡è¨­å‚™å·¥å…·å‡½æ•¸ (ä¸ä¾è³´ omni.isaac.core)
##

def ensure_cuda_tensor_fixed(data, device_id: int = 0):
    """ç¢ºä¿æ•¸æ“šæ˜¯ CUDA tensor (ä¿®å¾©ç‰ˆ)
    
    ä¸ä¾è³´ omni.isaac.coreï¼Œç›´æ¥ä½¿ç”¨ PyTorch
    
    Args:
        data: è¼¸å…¥æ•¸æ“š (numpy array, CPU tensor, æˆ–å·²ç¶“æ˜¯ CUDA tensor)
        device_id: CUDA è¨­å‚™ ID
    
    Returns:
        CUDA tensor (å¦‚æœ CUDA å¯ç”¨) æˆ– CPU tensor
    """
    if torch.cuda.is_available():
        device = torch.device(f"cuda:{device_id}")
    else:
        device = torch.device("cpu")
    
    if isinstance(data, torch.Tensor):
        return data.to(device, dtype=torch.float32)
    else:
        # numpy array æˆ–å…¶ä»–æ ¼å¼
        return torch.tensor(data, dtype=torch.float32, device=device)


def convert_positions_to_cuda_fixed(coords, orientations=None, device_id: int = 0):
    """å°‡ä½ç½®å’Œæ–¹å‘æ•¸æ“šè½‰æ›ç‚º CUDA tensor (ä¿®å¾©ç‰ˆ)
    
    å°ˆé–€ç”¨æ–¼ set_world_poses() ç­‰ PhysX API èª¿ç”¨
    ä¸ä¾è³´ omni.isaac.core
    
    Args:
        coords: ä½ç½®åº§æ¨™ (N, 3) æˆ– (3,)
        orientations: å››å…ƒæ•¸æ–¹å‘ (N, 4) æˆ– (4,)ï¼Œå¦‚æœç‚º None å‰‡ä½¿ç”¨é è¨­æ–¹å‘
        device_id: CUDA è¨­å‚™ ID
    
    Returns:
        tuple: (coords_tensor, orientations_tensor)
    """
    if torch.cuda.is_available():
        device = torch.device(f"cuda:{device_id}")
    else:
        device = torch.device("cpu")
    
    # è½‰æ›ä½ç½®
    if isinstance(coords, (list, tuple)):
        coords = torch.tensor(coords, dtype=torch.float32, device=device)
    elif isinstance(coords, torch.Tensor):
        coords = coords.to(device, dtype=torch.float32)
    else:
        # numpy array
        coords = torch.tensor(coords, dtype=torch.float32, device=device)
    
    # ç¢ºä¿æ˜¯ 2D tensor (N, 3)
    if coords.dim() == 1:
        coords = coords.unsqueeze(0)
    
    # è½‰æ›æ–¹å‘
    if orientations is None:
        # é è¨­æ–¹å‘ (ç„¡æ—‹è½‰): [0, 0, 0, 1]
        batch_size = coords.shape[0]
        orientations = torch.tensor([0.0, 0.0, 0.0, 1.0], device=device).repeat(batch_size, 1)
    else:
        if isinstance(orientations, (list, tuple)):
            orientations = torch.tensor(orientations, dtype=torch.float32, device=device)
        elif isinstance(orientations, torch.Tensor):
            orientations = orientations.to(device, dtype=torch.float32)
        else:
            # numpy array
            orientations = torch.tensor(orientations, dtype=torch.float32, device=device)
        
        # ç¢ºä¿æ˜¯ 2D tensor (N, 4)
        if orientations.dim() == 1:
            orientations = orientations.unsqueeze(0)
    
    return coords, orientations


##
# ä½¿ç”¨ç¯„ä¾‹ (ä¿®å¾©ç‰ˆ)
##

class GPUOptimizedUsageExampleFixed:
    """GPU å„ªåŒ–ä½¿ç”¨ç¯„ä¾‹ (ä¿®å¾©ç‰ˆ)"""
    
    @staticmethod
    def example_set_world_poses():
        """æ­£ç¢ºçš„ set_world_poses ä½¿ç”¨æ–¹å¼ (ä¿®å¾©ç‰ˆ)"""
        # âœ… æ­£ç¢ºï¼šä½¿ç”¨ä¿®å¾©ç‰ˆçš„ CUDA tensor è½‰æ›
        coords, orient = convert_positions_to_cuda_fixed(
            coords=[[-8.0, 32.0, -2.3]], 
            orientations=[[0.0, 0.0, 0.0, 1.0]],
            device_id=0
        )
        # self.cube_xform1.set_world_poses(coords, orient)  # é€™æ˜¯æ­£ç¢ºçš„ï¼
        
    @staticmethod
    def example_device_check():
        """æª¢æŸ¥è¨­å‚™è¨­å®šç¯„ä¾‹"""
        print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"ç•¶å‰ CUDA è¨­å‚™: {torch.cuda.current_device()}")
            print(f"CUDA è¨­å‚™åç¨±: {torch.cuda.get_device_name()}")
        else:
            print("ä½¿ç”¨ CPU æ¨¡å¼")
