╔══════════════════════════════════════════════════════════════════╗
║              🎯 訓練目標系統視覺化指南                           ║
╚══════════════════════════════════════════════════════════════════╝

問題: 訓練的目標是什麼？應該往哪裡去？
═══════════════════════════════════════════════════════════════════

✅ 訓練目標: 點到點導航（Point-to-Point Navigation）

任務:
  🤖 機器人從起點 → 導航到終點 🎯
  同時避開障礙物 🚧


場景示意圖（俯視圖）:
═══════════════════════════════════════════════════════════════════

    Y軸
     ↑
     │
  +5m│         ┌─────────────────────┐
     │         │   目標可能範圍      │
     │         │                     │
     │         │        🎯           │  ← 綠色球體
     │         │      終點目標        │     (隨機生成)
     │         │    (3-10m遠)        │
   0 ├─────────┤                     ├───────→ X軸
     │   🤖    │                     │
     │ 起點    │    🚧   🔴          │
     │(隨機)   │   障礙  障礙         │
  -5m│         └─────────────────────┘
     │
    -2m  0   3m                    10m

圖例:
──────────────────────────────────────────────────────
🤖  Nova Carter     - 起點: X∈(-2,2)m, Y∈(-2,2)m (隨機)
🎯  目標位置        - 終點: X∈(3,10)m, Y∈(-5,5)m (隨機)
🟢  綠色球體（可視化）- 標記目標位置（半徑30cm）
🔵  藍色箭頭        - debug_vis 顯示（GUI模式）
🚧  靜態障礙物      - 方塊
🔴  動態障礙物      - 紅色球體


目標位置說明:
═══════════════════════════════════════════════════════════════════

✅ 每個 Episode 隨機生成新目標
   └─ 距離: 3-10米（相對機器人起點）
   └─ 方向: 隨機（360度任意方向）

✅ 目標可視化（GUI 模式）
   └─ 🟢 綠色球體（半徑30cm）
   └─ 🔵 藍色箭頭（從機器人指向目標）

✅ 成功標準
   └─ 到達目標 0.5米 以內

✅ 目標更新
   └─ 到達目標時 → 立即生成新目標
   └─ 超時時 → 生成新目標
   └─ 每10秒 → 自動重新採樣


為什麼看不到目標？
═══════════════════════════════════════════════════════════════════

原因1: 使用 Headless 模式 ⭐ 最可能
  您的命令: ./isaaclab.sh -p ... --headless
  └─ 無 GUI，看不到任何視覺化
  
  解決: 移除 --headless
  ./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py \
      --task Isaac-Navigation-LocalPlanner-Carter-v0 \
      --num_envs 1

原因2: 目標標記太小
  當前: radius=0.3m (30cm)
  解決: 改為 radius=0.8m（第121行）

原因3: 顏色不明顯
  當前: 綠色 (0.0, 1.0, 0.0)
  解決: 改為黃色 (1.0, 1.0, 0.0)（第124行）

原因4: 高度太低
  當前: Z=0.3m
  解決: 改為 Z=1.5m（第126行）


如何看到目標？
═══════════════════════════════════════════════════════════════════

方法1: GUI 模式訓練（推薦）
──────────────────────────────────────────────────────
cd /home/aa/IsaacLab

./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py \
    --task Isaac-Navigation-LocalPlanner-Carter-v0 \
    --num_envs 1 \
    --max_iterations 20
    # 注意: 不使用 --headless

在 Isaac Sim 視窗中您會看到:
  🤖 機器人
  🎯 綠色球體（目標）
  🔵 藍色箭頭（指向目標）
  🚧 障礙物

方法2: Play 模式可視化（訓練後）
──────────────────────────────────────────────────────
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/play.py \
    --task Isaac-Navigation-LocalPlanner-Carter-v0 \
    --num_envs 1 \
    --checkpoint logs/rsl_rl/*/*/model_*.pt

這個模式專門用於可視化訓練好的策略


目標配置代碼位置
═══════════════════════════════════════════════════════════════════

📁 文件: source/.../local_planner_env_cfg.py

第 198-215 行: 目標命令配置（CommandsCfg）
  ├─ 第206行: debug_vis=True        啟用可視化
  ├─ 第208行: pos_x=(3.0, 10.0)     X範圍 3-10米
  ├─ 第209行: pos_y=(-5.0, 5.0)     Y範圍 -5到+5米
  └─ 第205行: resampling_time_range 每10秒重新生成

第 118-127 行: 目標標記（綠色球體）
  ├─ 第121行: radius=0.3            半徑 30cm
  ├─ 第124行: diffuse_color=綠色    🟢
  └─ 第126行: init_state=初始位置   (8,0,0.3)


機器人如何知道目標在哪？
═══════════════════════════════════════════════════════════════════

觀測空間包含目標相對位置:
  goal_position_in_robot_frame()
  └─ 輸出: [相對X, 相對Y]  (2維向量)

例如:
  觀測 = [5.2, -2.3]
  └─ 目標在機器人前方5.2米、左邊2.3米

獎勵引導:
  - 每步接近目標 → +獎勵
  - 到達目標(<0.5m) → +100 大獎勵
  - 遠離目標 → -獎勵（隱含）


快速修改讓目標更明顯
═══════════════════════════════════════════════════════════════════

vim +118 source/.../local_planner_env_cfg.py

修改第 118-127 行:
  goal_marker = RigidObjectCfg(
      prim_path="{ENV_REGEX_NS}/GoalMarker",
      spawn=sim_utils.SphereCfg(
          radius=0.8,  # ← 從 0.3 改為 0.8（更大）
          visual_material=sim_utils.PreviewSurfaceCfg(
              diffuse_color=(1.0, 1.0, 0.0),  # ← 改為黃色
              emissive_color=(1.0, 1.0, 0.0), # ← 添加發光
              emissive_intensity=2.0,
          ),
      ),
      init_state=RigidObjectCfg.InitialStateCfg(
          pos=(8.0, 0.0, 1.5)  # ← 從 0.3 改為 1.5（更高）
      ),
  )


成功的訓練應該是:
═══════════════════════════════════════════════════════════════════

在 GUI 模式下觀察到:
  1. 🤖 機器人朝 🎯 綠色球體移動
  2. 避開 🚧 障礙物
  3. 到達目標 → 🎯 移動到新位置 → 機器人再次導航
  4. Mean reward 逐漸上升
  5. Episode_Reward/reached_goal > 0


═══════════════════════════════════════════════════════════════════
📖 詳細文檔: md/GOAL_SYSTEM_EXPLANATION.md
═══════════════════════════════════════════════════════════════════
