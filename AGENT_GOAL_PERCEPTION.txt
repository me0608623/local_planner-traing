╔══════════════════════════════════════════════════════════════════╗
║          🤖 Agent 如何感知目標位置？                             ║
╚══════════════════════════════════════════════════════════════════╝

核心答案：
═══════════════════════════════════════════════════════════════════

✅ Agent 通過 觀測空間（Observation Space）直接獲得目標信息

❌ 不使用 ROS 通訊！

🎯 目標以 相對位置 形式提供（機器人座標系）


數據流示意圖：
═══════════════════════════════════════════════════════════════════

┌─────────────────────────────────────────────────┐
│  1. 目標生成（世界座標）                         │
│     CommandManager                              │
│     └─ goal_pos_w = [8.5, -2.3, 0.0]           │
│        （世界座標系）                            │
└─────────────────────────────────────────────────┘
                      ↓
┌─────────────────────────────────────────────────┐
│  2. 機器人狀態                                   │
│     robot_pos_w = [1.2, -0.8, 0.0]             │
│     robot_quat_w = [0.707, 0, 0, 0.707]        │
│     （機器人位置和朝向）                         │
└─────────────────────────────────────────────────┘
                      ↓
┌─────────────────────────────────────────────────┐
│  3. 座標轉換                                     │
│     goal_position_in_robot_frame()              │
│     ├─ 計算相對位置：goal - robot              │
│     └─ 轉換到機器人座標系                       │
│     輸出：[7.2, -1.5]                           │
│     （機器人前方7.2米、右邊1.5米）              │
└─────────────────────────────────────────────────┘
                      ↓
┌─────────────────────────────────────────────────┐
│  4. 組裝觀測向量                                 │
│     Observation = [                             │
│       LiDAR[360],      ← 障礙物信息             │
│       velocity[6],     ← 自身狀態               │
│       goal_pos[2],     ← 目標信息 ⭐            │
│       distance[1]      ← 目標距離               │
│     ]                                           │
│     總維度：~369維                               │
└─────────────────────────────────────────────────┘
                      ↓
┌─────────────────────────────────────────────────┐
│  5. 神經網路（Actor）                            │
│     Input[369] → Hidden[256,256,128] → Output[2]│
│                                                 │
│     輸出動作：[v_linear, v_angular]             │
└─────────────────────────────────────────────────┘


Agent 的"視角"（機器人座標系）：
═══════════════════════════════════════════════════════════════════

        Y_robot (左)
           ↑
           │
           │       🎯 目標
           │      /  [7.2, -1.5]
           │     /
           │    /
           │   /
       🤖 ├──────────→ X_robot (前)
           │
           │
           ↓
        (後方)

Agent 看到的目標信息：
  dx =  7.2  （目標在前方7.2米）
  dy = -1.5  （目標在右邊1.5米）
  distance = 7.35m


為什麼不用世界座標？
═══════════════════════════════════════════════════════════════════

世界座標問題：
  🤖 朝北時，目標在 [10, 0]   → 需要前進
  🤖 朝南時，目標在 [10, 0]   → 需要後退
  ❌ 同樣的輸入，不同的動作 → 難以學習

機器人座標優點：
  🤖 不管朝哪，"前方10米" → 都是前進
  ✅ 相同的輸入，相同的動作 → 容易學習


Agent 接收的完整信息：
═══════════════════════════════════════════════════════════════════

每個時間步（0.04秒），Agent 知道：

1. 周圍環境 🔍
   LiDAR[360維]:
   - 0° (前): 距離 9.8m（沒障礙）
   - 45°(左前): 距離 3.2m（有障礙！）
   - 90°(左): 距離 10.0m（沒障礙）
   - ...

2. 自身狀態 🏃
   速度[6維]:
   - 正在以 1.2m/s 前進
   - 正在以 0.3rad/s 左轉

3. 目標信息 🎯 ⭐
   目標位置[2維]:
   - 前方 7.2米
   - 右邊 1.5米
   
   目標距離[1維]:
   - 總距離 7.35米

4. 歷史（可選）
   - 上一步的動作


ROS 在哪裡用？
═══════════════════════════════════════════════════════════════════

訓練階段（當前）：
  ❌ 不使用 ROS
  ✅ 純模擬器內部數據流
  ✅ GPU Tensor 直接傳遞
  ✅ 高效、無延遲

部署階段（未來）：
  ✅ 使用 ROS
  - /goal_pose (訂閱目標)
  - /scan (訂閱 LiDAR)
  - /cmd_vel (發布速度命令)


代碼位置：
═══════════════════════════════════════════════════════════════════

觀測配置:
  📁 local_planner_env_cfg.py
  📍 第 178-187 行 - 目標觀測配置

觀測實現:
  📁 mdp/observations.py
  📍 第 89-111 行 - goal_position_in_robot_frame()
  📍 第 114-131 行 - distance_to_goal()

座標轉換:
  使用 Isaac Lab 的 math_utils.quat_apply_inverse()
  將世界座標轉換為機器人座標


關鍵代碼：
═══════════════════════════════════════════════════════════════════

# 觀測配置（告訴系統給 agent 什麼）
goal_position = ObsTerm(
    func=mdp.goal_position_in_robot_frame,  # 調用函數
    params={"command_name": "goal_command"}, # 參數
)

# 實際計算（轉換座標）
def goal_position_in_robot_frame(env, command_name):
    # 1. 獲取目標（世界座標）
    goal_pos_w = env.command_manager.get_command(command_name)[:, :3]
    
    # 2. 獲取機器人狀態
    robot_pos_w = robot.data.root_pos_w
    robot_quat_w = robot.data.root_quat_w
    
    # 3. 計算相對位置
    goal_rel_w = goal_pos_w - robot_pos_w
    
    # 4. 轉換到機器人座標系 ⭐
    goal_rel_b = quat_apply_inverse(robot_quat_w, goal_rel_w)
    
    # 5. 返回 2D 位置
    return goal_rel_b[:, :2]  # [dx, dy]


總結：
═══════════════════════════════════════════════════════════════════

✅ Agent 已知目標位置
   └─ 以相對位置形式 [dx, dy]

✅ 每個時間步更新
   └─ 機器人移動，相對位置改變

✅ 直接在觀測空間中
   └─ 與 LiDAR、速度一起輸入神經網路

❌ 不用 ROS
   └─ 模擬訓練直接用 GPU Tensor

📖 詳細文檔: md/HOW_AGENT_SEES_GOAL.md
═══════════════════════════════════════════════════════════════════
